# STT/TTS í†µí•© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

STT(Speech-to-Text)ì™€ TTS(Text-to-Speech)ë¥¼ í”„ë¡œì íŠ¸ì— í†µí•©í•˜ëŠ” ë°©ë²•ê³¼ ì—°ê²° êµ¬ì¡°ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ¯ ì¶”ì²œ ì•„í‚¤í…ì²˜: í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹

### êµ¬ì¡° ê°œìš”

```
[ì‚¬ìš©ì ìŒì„±] 
    â†“
[ë¸Œë¼ìš°ì € Web Speech API - STT] 
    â†“
[í…ìŠ¤íŠ¸ ì „ì†¡] â†’ [ë°±ì—”ë“œ Flask API]
    â†“
[AI ì‘ë‹µ ìƒì„±] â†’ [ìŠ¤ìº  ë¶„ì„]
    â†“
[í…ìŠ¤íŠ¸ ì‘ë‹µ ë°˜í™˜]
    â†“
[ë¸Œë¼ìš°ì € Web Speech API - TTS]
    â†“
[AI ìŒì„± ì¬ìƒ]
```

### ì„ íƒ ì´ìœ 

1. **STTëŠ” í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ (Web Speech API)**
   - âœ… API í‚¤ ë¶ˆí•„ìš”
   - âœ… ë¹ ë¥¸ ì‘ë‹µ ì†ë„
   - âœ… ë¬´ë£Œ ì‚¬ìš©
   - âœ… ì‹¤ì‹œê°„ ì²˜ë¦¬

2. **TTSë„ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ (Web Speech API)**
   - âœ… API í‚¤ ë¶ˆí•„ìš”
   - âœ… ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±
   - âœ… ë¬´ë£Œ ì‚¬ìš©
   - âœ… ì¦‰ì‹œ ì¬ìƒ ê°€ëŠ¥

3. **ë°±ì—”ë“œëŠ” í…ìŠ¤íŠ¸ ë¶„ì„ì— ì§‘ì¤‘**
   - âœ… AI ì‘ë‹µ ìƒì„±
   - âœ… ìŠ¤ìº  íŒ¨í„´ ë¶„ì„
   - âœ… ë¦¬í¬íŠ¸ ìƒì„±

---

## ğŸ”§ êµ¬í˜„ ë°©ë²•

### 1. í”„ë¡ íŠ¸ì—”ë“œ: Web Speech API í†µí•©

#### STT (ìŒì„± â†’ í…ìŠ¤íŠ¸)

```javascript
// ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

class STTService {
  constructor() {
    this.recognition = null;
    this.isListening = false;
  }

  startListening(onResult, onError) {
    if (!SpeechRecognition) {
      console.error('Speech Recognition API not supported');
      return;
    }

    this.recognition = new SpeechRecognition();
    this.recognition.lang = 'ko-KR'; // í•œêµ­ì–´
    this.recognition.continuous = true; // ì—°ì† ì¸ì‹
    this.recognition.interimResults = true; // ì¤‘ê°„ ê²°ê³¼ë„ ë°›ê¸°

    this.recognition.onresult = (event) => {
      let finalTranscript = '';
      let interimTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript + ' ';
        } else {
          interimTranscript += transcript;
        }
      }

      if (finalTranscript) {
        onResult(finalTranscript.trim());
      }
    };

    this.recognition.onerror = (event) => {
      onError(event.error);
    };

    this.recognition.start();
    this.isListening = true;
  }

  stopListening() {
    if (this.recognition && this.isListening) {
      this.recognition.stop();
      this.isListening = false;
    }
  }
}
```

#### TTS (í…ìŠ¤íŠ¸ â†’ ìŒì„±)

```javascript
// ìŒì„± í•©ì„± ì„œë¹„ìŠ¤
class TTSService {
  speak(text, onEnd) {
    if (!window.speechSynthesis) {
      console.error('Speech Synthesis API not supported');
      return;
    }

    // ì´ì „ ìŒì„± ì¤‘ì§€
    window.speechSynthesis.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR'; // í•œêµ­ì–´
    utterance.rate = 1.0; // ì†ë„ (0.1 ~ 10)
    utterance.pitch = 1.0; // ìŒë†’ì´ (0 ~ 2)
    utterance.volume = 1.0; // ë³¼ë¥¨ (0 ~ 1)

    utterance.onend = () => {
      if (onEnd) onEnd();
    };

    utterance.onerror = (event) => {
      console.error('TTS Error:', event);
    };

    window.speechSynthesis.speak(utterance);
  }

  stop() {
    window.speechSynthesis.cancel();
  }

  pause() {
    window.speechSynthesis.pause();
  }

  resume() {
    window.speechSynthesis.resume();
  }
}
```

### 2. í†µí™” íë¦„ í†µí•©

```javascript
// í†µí™” ì¤‘ ìŒì„± ì²˜ë¦¬ íë¦„
class VoiceCallHandler {
  constructor() {
    this.stt = new STTService();
    this.tts = new TTSService();
    this.callId = null;
    this.conversationHistory = [];
  }

  async startCall(callerNumber) {
    // 1. ë°±ì—”ë“œì— í†µí™” ì‹œì‘ ì•Œë¦¼
    const response = await callService.startCall(callerNumber);
    this.callId = response.call_id;

    // 2. STT ì‹œì‘ (ìƒëŒ€ë°© ìŒì„± ë“£ê¸°)
    this.stt.startListening(
      (text) => this.handleCallerSpeech(text),
      (error) => this.handleSTTError(error)
    );

    // 3. AI ì¸ì‚¬ë§ ì¬ìƒ
    this.tts.speak('ì•ˆë…•í•˜ì„¸ìš”, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?');
  }

  async handleCallerSpeech(text) {
    // 1. ìƒëŒ€ë°© ë§ì„ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€
    this.conversationHistory.push({
      speaker: 'caller',
      text: text,
      timestamp: new Date().toISOString()
    });

    // 2. ë°±ì—”ë“œë¡œ ì „ì†¡í•˜ì—¬ AI ì‘ë‹µ ìƒì„±
    const response = await callService.processAudio(this.callId, text);

    // 3. AI ì‘ë‹µì„ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€
    this.conversationHistory.push({
      speaker: 'ai',
      text: response.ai_response,
      timestamp: new Date().toISOString()
    });

    // 4. ìŠ¤ìº  ì ìˆ˜ ì—…ë°ì´íŠ¸
    this.updateScamScore(response.scam_score);

    // 5. AI ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ì¬ìƒ
    this.tts.speak(response.ai_response, () => {
      // ì¬ìƒ ì™„ë£Œ í›„ ë‹¤ì‹œ STT ëŒ€ê¸°
      console.log('AI ì‘ë‹µ ì¬ìƒ ì™„ë£Œ');
    });
  }

  endCall() {
    // 1. STT ì¤‘ì§€
    this.stt.stopListening();

    // 2. TTS ì¤‘ì§€
    this.tts.stop();

    // 3. ë°±ì—”ë“œì— í†µí™” ì¢…ë£Œ ì•Œë¦¼ ë° ë¦¬í¬íŠ¸ ìƒì„±
    callService.endCall(this.callId, this.conversationHistory);
  }
}
```

---

## ğŸ”„ ë°ì´í„° íë¦„ ìƒì„¸

### í†µí™” ì‹œì‘ â†’ ìŒì„± ì¸ì‹ â†’ AI ì‘ë‹µ â†’ ìŒì„± ì¬ìƒ

```
1. [ì‚¬ìš©ì] "AI ëŒ€ì‹  ë°›ê¸°" í´ë¦­
   â†“
2. [í”„ë¡ íŠ¸ì—”ë“œ] STT ì‹œì‘ (Web Speech API)
   â†“
3. [ìƒëŒ€ë°©] ìŒì„± ì…ë ¥
   â†“
4. [ë¸Œë¼ìš°ì €] STT â†’ í…ìŠ¤íŠ¸ ë³€í™˜
   â†“
5. [í”„ë¡ íŠ¸ì—”ë“œ] POST /api/call/process-audio
   {
     "call_id": "call_123",
     "audio_data": "ì•ˆë…•í•˜ì„¸ìš”, ê¸ˆìœµê°ë…ì›ì…ë‹ˆë‹¤"
   }
   â†“
6. [ë°±ì—”ë“œ] 
   - STT ì„œë¹„ìŠ¤ (í˜„ì¬ëŠ” í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°›ìŒ)
   - ìŠ¤ìº  ë¶„ì„
   - AI ì‘ë‹µ ìƒì„±
   â†“
7. [ë°±ì—”ë“œ ì‘ë‹µ]
   {
     "transcript": "ì•ˆë…•í•˜ì„¸ìš”, ê¸ˆìœµê°ë…ì›ì…ë‹ˆë‹¤",
     "ai_response": "ì•„... ë„¤? ê¸ˆìœµê°ë…ì›ì´ìš”?",
     "scam_score": 0.15
   }
   â†“
8. [í”„ë¡ íŠ¸ì—”ë“œ]
   - ëŒ€í™” ë‚´ì—­ ì—…ë°ì´íŠ¸
   - ìŠ¤ìº  ì ìˆ˜ ì—…ë°ì´íŠ¸
   - TTSë¡œ AI ì‘ë‹µ ì¬ìƒ
   â†“
9. [ë¸Œë¼ìš°ì €] TTS â†’ ìŒì„± ì¬ìƒ
   â†“
10. [ë°˜ë³µ] 3ë²ˆë¶€í„° ë°˜ë³µ
```

---

## ğŸ“ ë°±ì—”ë“œ API ìˆ˜ì • ì‚¬í•­

### í˜„ì¬ API êµ¬ì¡° ìœ ì§€

ë°±ì—”ë“œëŠ” ì´ë¯¸ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ í° ë³€ê²½ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥:

```python
# backend/app.pyì˜ /api/call/process-audio ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/call/process-audio', methods=['POST'])
def process_audio():
    data = request.json
    call_id = data.get('call_id')
    audio_data = data.get('audio_data')  # ì´ë¯¸ í…ìŠ¤íŠ¸ë¡œ ë°›ìŒ
    
    # STTëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    transcript = audio_data  # ë˜ëŠ” í•„ìš”ì‹œ ì¶”ê°€ ì²˜ë¦¬
    
    # ìŠ¤ìº  ë¶„ì„
    scam_score = scam_analyzer.analyze(transcript)
    
    # AI ì‘ë‹µ ìƒì„±
    ai_response = ai_service.generate_response(transcript, scam_score)
    
    return jsonify({
        "transcript": transcript,
        "ai_response": ai_response,
        "scam_score": scam_score
    })
```

**ë³€ê²½ ì‚¬í•­**: `audio_data`ê°€ ì´ë¯¸ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ STT ë³€í™˜ ë‹¨ê³„ ìƒëµ ê°€ëŠ¥

---

## ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ í†µí•© ì˜ˆì‹œ

### IncomingCallScreen ìˆ˜ì •

```javascript
function IncomingCallScreen({ callerNumber, onEndCall, onReport }) {
  const [callStatus, setCallStatus] = useState('incoming');
  const [callId, setCallId] = useState(null);
  const [conversationHistory, setConversationHistory] = useState([]);
  const [scamScore, setScamScore] = useState(0);
  
  // STT/TTS ì„œë¹„ìŠ¤
  const sttServiceRef = useRef(null);
  const ttsServiceRef = useRef(null);
  const voiceCallHandlerRef = useRef(null);

  useEffect(() => {
    // STT/TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    sttServiceRef.current = new STTService();
    ttsServiceRef.current = new TTSService();
    voiceCallHandlerRef.current = new VoiceCallHandler();
    
    return () => {
      // ì •ë¦¬
      if (sttServiceRef.current) {
        sttServiceRef.current.stopListening();
      }
      if (ttsServiceRef.current) {
        ttsServiceRef.current.stop();
      }
    };
  }, []);

  const handleAIAccept = async () => {
    try {
      setCallStatus('ai_talking');
      
      // í†µí™” ì‹œì‘
      await voiceCallHandlerRef.current.startCall(callerNumber);
      
      // í†µí™” ID ì €ì¥
      const response = await callService.startCall(callerNumber);
      setCallId(response.call_id);
      
    } catch (error) {
      alert('í†µí™” ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const handleEndCall = async () => {
    // ìŒì„± ì²˜ë¦¬ ì¤‘ì§€
    voiceCallHandlerRef.current.endCall();
    
    // ë¦¬í¬íŠ¸ ìƒì„±
    // ... ê¸°ì¡´ ë¡œì§
  };

  // ... ë‚˜ë¨¸ì§€ ì½”ë“œ
}
```

---

## ğŸ”§ ëŒ€ì•ˆ: ë°±ì—”ë“œ STT/TTS ì‚¬ìš©

ë§Œì•½ ë°±ì—”ë“œì—ì„œ STT/TTSë¥¼ ì²˜ë¦¬í•˜ê³  ì‹¶ë‹¤ë©´:

### ì˜µì…˜ 1: Google Cloud Speech-to-Text (STT)

```python
# backend/services/stt_service.py
from google.cloud import speech

class STTService:
    def __init__(self):
        self.client = speech.SpeechClient()
    
    def transcribe(self, audio_data: bytes) -> str:
        audio = speech.RecognitionAudio(content=audio_data)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
            sample_rate_hertz=16000,
            language_code="ko-KR"
        )
        
        response = self.client.recognize(config=config, audio=audio)
        return response.results[0].alternatives[0].transcript
```

### ì˜µì…˜ 2: Google Cloud Text-to-Speech (TTS)

```python
# backend/services/tts_service.py
from google.cloud import texttospeech

class TTSService:
    def __init__(self):
        self.client = texttospeech.TextToSpeechClient()
    
    def synthesize(self, text: str) -> bytes:
        synthesis_input = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )
        
        response = self.client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        return response.audio_content
```

### ë°±ì—”ë“œ STT/TTS ì‚¬ìš© ì‹œ API êµ¬ì¡°

```python
# ìŒì„± ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ì²˜ë¦¬
@app.route('/api/call/process-audio', methods=['POST'])
def process_audio():
    audio_file = request.files['audio']  # ì˜¤ë””ì˜¤ íŒŒì¼
    audio_data = audio_file.read()
    
    # STT
    transcript = stt_service.transcribe(audio_data)
    
    # AI ì‘ë‹µ ìƒì„±
    ai_response = ai_service.generate_response(transcript)
    
    # TTS
    audio_response = tts_service.synthesize(ai_response)
    
    return jsonify({
        "transcript": transcript,
        "ai_response": ai_response,
        "audio_response": base64.b64encode(audio_response).decode('utf-8')
    })
```

---

## ğŸ’¡ ì¶”ì²œ ë°©ì‹ ë¹„êµ

| ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì¶”ì²œë„ |
|------|------|------|--------|
| **ì›¹ ë¸Œë¼ìš°ì € API** | âœ… ë¬´ë£Œ<br>âœ… ë¹ ë¥¸ ì‘ë‹µ<br>âœ… API í‚¤ ë¶ˆí•„ìš”<br>âœ… ì‹¤ì‹œê°„ ì²˜ë¦¬ | âŒ ë¸Œë¼ìš°ì € í˜¸í™˜ì„±<br>âŒ ì •í™•ë„ ì œí•œ | â­â­â­â­â­ |
| **ë°±ì—”ë“œ STT/TTS** | âœ… ë†’ì€ ì •í™•ë„<br>âœ… ì¼ê´€ì„±<br>âœ… ë‹¤ì–‘í•œ ì–¸ì–´ | âŒ API í‚¤ í•„ìš”<br>âŒ ë¹„ìš© ë°œìƒ<br>âŒ ì§€ì—° ì‹œê°„ | â­â­â­ |

### ìµœì¢… ì¶”ì²œ: **ì›¹ ë¸Œë¼ìš°ì € API ë°©ì‹**

**ì´ìœ :**
1. í”„ë¡œí† íƒ€ì… ë‹¨ê³„ì—ì„œëŠ” ë¬´ë£Œì´ê³  ë¹ ë¦„
2. ë°±ì—”ë“œëŠ” í…ìŠ¤íŠ¸ ë¶„ì„ì— ì§‘ì¤‘ ê°€ëŠ¥
3. ë‚˜ì¤‘ì— í•„ìš”ì‹œ ë°±ì—”ë“œë¡œ ì „í™˜ ê°€ëŠ¥

---

## ğŸš€ êµ¬í˜„ ë‹¨ê³„

### Phase 1: ê¸°ë³¸ STT/TTS í†µí•©
1. âœ… Web Speech API ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ìƒì„±
2. âœ… í†µí™” í™”ë©´ì— STT/TTS í†µí•©
3. âœ… ìŒì„± ì…ë ¥ â†’ í…ìŠ¤íŠ¸ â†’ ë°±ì—”ë“œ ì „ì†¡
4. âœ… ë°±ì—”ë“œ ì‘ë‹µ â†’ TTS ì¬ìƒ

### Phase 2: ê°œì„ 
1. âš ï¸ ìŒì„± í’ˆì§ˆ ê°œì„ 
2. âš ï¸ ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
3. âš ï¸ ìŒì„± ì¸ì‹ ì •í™•ë„ í–¥ìƒ

### Phase 3: ê³ ê¸‰ ê¸°ëŠ¥
1. âŒ ë°±ì—”ë“œ STT/TTS ì˜µì…˜ ì¶”ê°€
2. âŒ ìŒì„± ë…¹ìŒ ë° ì¬ìƒ
3. âŒ ë‹¤êµ­ì–´ ì§€ì›

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Web Speech API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [Speech Recognition API](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition)
- [Speech Synthesis API](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis)
- [Google Cloud Speech-to-Text](https://cloud.google.com/speech-to-text)
- [Google Cloud Text-to-Speech](https://cloud.google.com/text-to-speech)

---

## ğŸ” ë¸Œë¼ìš°ì € í˜¸í™˜ì„±

### Speech Recognition API
- âœ… Chrome/Edge: ì§€ì›
- âœ… Safari: ë¶€ë¶„ ì§€ì› (webkit)
- âŒ Firefox: ë¯¸ì§€ì›

### Speech Synthesis API
- âœ… ëª¨ë“  ì£¼ìš” ë¸Œë¼ìš°ì € ì§€ì›

---

## ğŸ’» êµ¬í˜„ ì˜ˆì‹œ ì½”ë“œ ìœ„ì¹˜

êµ¬í˜„ ì‹œ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ìˆ˜ì •/ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤:

1. **í”„ë¡ íŠ¸ì—”ë“œ ì„œë¹„ìŠ¤ ì¶”ê°€**
   - `frontend/services/stt-service.js` (ì‹ ê·œ)
   - `frontend/services/tts-service.js` (ì‹ ê·œ)
   - `frontend/services/voice-call-handler.js` (ì‹ ê·œ)

2. **í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ ìˆ˜ì •**
   - `frontend/app-full.js`ì˜ `IncomingCallScreen` ì»´í¬ë„ŒíŠ¸

3. **ë°±ì—”ë“œ (ì„ íƒì‚¬í•­)**
   - `backend/services/stt_service.py` (ì‹¤ì œ API ì—°ë™)
   - `backend/services/tts_service.py` (ì‹ ê·œ, ì„ íƒì‚¬í•­)

